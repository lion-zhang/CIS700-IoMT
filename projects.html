<!doctype html>
<html>
<head>
  <title>Internet of Medical Things - Term Projects</title>
  <link rel=stylesheet href="index.css" type="text/css" media=screen>
</head>
<body>
<h2>CIS 700: Topics in Internet of Medical Things, Spring 2024</h2>


<p class="header">
<a href="index.html">Home</a> |
<!--<a href="lectures.html">Lectures</a> | -->
<a href="reading.html">Reading List</a> | 
<a href="presentation.html">Schedule</a> | 
<a href="projects.html">Projects</a></p>

<hr>

<h2> Possible Term Projects </h2>

	<ol>
		<li> Capture fundus images from cellphone cameras to train model </li>
		<ul>
			<li> Provide cellphone attachment for capturing images </li>
			<li> <a href="https://eyewiki.aao.org/Smartphone_Funduscopy_-_How_to_Use_Smartphone_to_Take_Fundus_Photographs">Smartphone Funduscopy - How to Use Smartphone to Take Fundus Photographs - EyeWiki (aao.org)</a> </li>
			<li> Students implement some programs to acquire fundus images from cellphones. </li>
			<li> Comparison of fundus image acquired from cellphone vs standard medical device (portable fundus imaging device that Liz has from Hillrom) </li>
			<li> Potential deliverable: some model learned from acquired data </li>
			<li> Potential deliverable: translation of cellphone captured fundus image to medical device captured fundus image </li>
		</ul>
		<li>Gait analysis - using IMU and accelerometers</li>
		<ul>
			<li>Option 1: Using an ego vs non-ego (i.e. head-on vs overhead) camera angle</li>
			<li>Option 2: comparison of IMU-derived (privacy-preserving) gait vs ground truth video-derived gait</li>
			<li>Option 3: New method for gait analysis </li>
		</ul>
		<li> Measuring degree of word-finding difficulty in a person's speech related to some neurodegenerative - lifelong evaluation</li>
		<li> Loneliness detection and interventions </li>
		<li> Glaucoma detection and progression prediction </li>
		<li> Smart Alarms</li>
		<li> Dermatology </li>
	</ol>

<body>
</body>
</html>
